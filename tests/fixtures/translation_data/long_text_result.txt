
Rag agent execution result is :
上周，我在美国国会就人工智能和监管话题发表了演讲，出席该活动的包括立法者和商界领袖。我感到鼓舞的是，开源社区在抵制可能扼杀创新的法规方面取得了进展。但开源软件的反对者们继续转变他们的论点，最新的担忧集中在开源软件对国家安全的影响上。我希望我们都能继续保护开源软件！

根据我与立法者的交流，我很受鼓舞，美国联邦政府在正确认识人工智能风险方面取得了进展。需要明确的是，必须设定适当的限制。但这些限制应适用于具体的人工智能应用，而非通用人工智能技术。尽管如此，正如我之前所写，一些公司热衷于限制开源，可能是为了保护他们在专有模型上的巨额投资价值，并遏制竞争对手的发展。看到他们的论点随时间演变，这很有趣。

例如，大约12个月前，人工智能安全中心的“人工智能风险声明”警告说，人工智能可能导致人类灭绝，并引发了人们对人工智能接管的担忧。这让华盛顿的领导人感到担忧。但许多人工智能领域的人都指出，这种反乌托邦的科幻情景在现实中几乎站不住脚。大约六个月后，当我在美国参议院的人工智能洞察论坛作证时，立法者们不再担心人工智能的接管问题。随后，反对开源的人改变了论调。他们的主要论点变成了AI可能帮助制造生物武器的风险。不久之后，OpenAI和RAND指出当前AI并未显著提升恶意行为者制造生物武器的能力。这种关于AI助力制造生物武器的担忧已有所减轻。当然，无论是否有AI的帮助，恶意行为者使用生物武器的可能性依然是国际社会关注的重大问题。最新的反对开源人工智能的理由已转向国家安全。开源的反对者认为美国应确保其对手无法获取最新的基础模型。尽管我不希望专制政府使用人工智能，特别是用于不义之战，但大型语言模型的秘密已被揭开，如果民主国家限制访问，专制国家将填补这一空缺。将来某一天，某个孩子向人工智能系统提问关于民主、新闻自由的作用或独立司法机构在维护法治方面的作用时，我希望人工智能能够体现民主价值观，而不是优先考虑专制领导人目标，例如人权。我离开华盛顿时对我们在未来所取得的进展感到乐观。一年前，立法者似乎将80%的时间花在讨论人工智能监管措施上，只有20%的时间用于投资创新方面。我很高兴这个比例已经颠倒，现在更多地讨论投资创新。

展望美国联邦政府之外，全球有很多司法管辖区。不幸的是，支持扼杀人工智能发展的监管论点仍然在不断增加。但我从访问华盛顿时和其他国家首都的经历中学到，与监管机构交谈确实会有影响。如果你有机会与任何级别的监管机构交谈，我希望你能尽你所能帮助政府更好地理解人工智能。