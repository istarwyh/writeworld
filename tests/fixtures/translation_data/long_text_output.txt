
Rag agent execution result is :
上周，我在美国国会就人工智能和监管问题发表演讲，出席活动的有立法者和商界领袖。我对开源社区成功抵御了可能扼杀创新的监管措施所取得的进展感到鼓舞。然而，开源的反对者们仍在不断调整他们的论点，最近的担忧集中于开源对国家安全的影响。我希望我们都能继续保护开源！

根据我与立法者的交流，我很高兴看到美国联邦政府在正确理解人工智能风险方面取得了实质性的进展。需要明确的是，我们需要设置护栏。但是这些护栏应当应用于人工智能的具体应用，而非通用的人工智能技术。然而，正如我之前所写的，一些公司热衷于限制开源，可能是因为他们希望保护在专有模型上的巨额投资价值，并阻止竞争对手。观察到他们的论点随着时间的变化而改变，这非常有趣。

例如，大约12个月前，人工智能安全中心的“关于人工智能风险的声明”警告说，人工智能可能导致人类灭绝，并引发了人们对于人工智能将要接管的担忧。这让华盛顿的领导人们感到恐慌。但许多人工智能专家指出，这种反乌托邦的科幻情景在现实中几乎毫无根据。大约六个月后，当我在美国参议院人工智能洞察论坛作证时，立法者们不再过多担忧人工智能的接管问题。随后，反对开源的人改变了论调。他们的主要论点转向了AI助力制造生物武器的风险。不久后，OpenAI和兰德公司指出，现有的AI技术并没有显著提升恶意行为者制造生物武器的能力。这种对AI赋能生物武器的担忧已有所缓解。当然，不论是否有AI的帮助，恶意行为者是否使用生物武器仍然是国际社会高度关注的问题。阻止开源人工智能的最新论点转向了国家安全。人工智能对经济竞争和战争都具有重要作用，开源的反对者认为美国应确保其对手无法获取最新的基础模型。尽管我不希望专制政权使用人工智能，尤其是用于不正义的战争，但大型语言模型的秘密已被揭露，如果民主国家限制访问，专制国家将填补这一空白。将来某一天，某个孩子可能会向人工智能系统提问关于民主、新闻自由的作用，以及独立司法机构如何维持法治的问题，我希望人工智能能体现民主价值观，而不是优先于人权而偏向专制领导人的目标。我离开华盛顿时对所取得的进展感到乐观。一年前，立法者似乎将80%的时间花在讨论AI监管措施上，只有20%的时间用于投资创新。我很高兴这个比例已经翻转，现在更多地讨论创新投资。

展望美国联邦政府之外，全球有许多司法辖区。不幸的是，支持扼杀AI发展的监管论点仍然在不断增加。但我从访问华盛顿和其他国家首都的经历中学到了与监管机构交流确实会产生影响。如果你有机会与任何级别的监管机构交流，我希望你能尽你所能帮助政府更好地理解AI。