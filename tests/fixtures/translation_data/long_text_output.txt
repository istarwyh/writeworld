
Rag agent execution result is :
上周，我在美国国会就人工智能和监管问题发表演讲，活动吸引了立法者和商业领袖参加。我对开源社区成功抵御可能抑制创新的监管措施所取得的进展感到鼓舞。但是，开源的反对者们正在不断转变他们的论调，最近的担忧集中在开源对国家安全的影响上。我希望我们都能够继续保护开源！

根据我与立法者的交流，我很高兴地看到美国联邦政府在正确认识人工智能风险方面取得了进展。请明确，需要设立护栏。但它们应适用于人工智能应用，而非通用人工智能技术。尽管如此，正如我之前所写的，一些公司热衷于限制开源，可能是因为他们希望保护对专有模型的巨大投资价值，并遏制竞争对手。看到他们的论点随着时间的推移而发生变化是非常有趣的。

例如，大约12个月前，人工智能安全中心发布的“关于人工智能风险的声明”警告称，人工智能可能会导致人类灭绝，并引发了人们对于人工智能接管的担忧。这让华盛顿的领导人感到恐慌。但许多人工智能领域的专家指出，这种反乌托邦的科幻场景在现实中几乎没有任何根据。大约六个月后，当我在美国参议院人工智能洞察论坛作证时，立法者们不再那么担心人工智能会接管。随后，反对开源的人改变了论调。他们的主要论点变成了AI帮助制造生物武器的风险。不久之后，OpenAI和RAND指出当前的AI并未显著提升作恶者制造生物武器的能力。对AI制造生物武器的担忧已经减轻。当然，无论是否有AI的帮助，恶意行为者使用生物武器的可能性依然是国际社会关注的重点问题。反对开源AI的最新论点转向了国家安全。开源软件的反对者认为美国应该确保其对手无法获取最新的基础模型。尽管我不希望专制政权利用AI，尤其是用于不义之战，但是大型语言模型的秘密已经公开，如果民主国家限制访问，专制国家将填补这个空缺。当有一天某个孩子向AI系统提问关于民主、新闻自由的作用，或独立司法机构如何维护法治的问题时，我希望AI能体现民主价值观，而不是优先考虑专制领导人而非人权等目标。我离开华盛顿时对未来的发展感到乐观。一年前，立法者似乎把80%的时间花在讨论AI监管措施上，而只有20%的时间用于促进创新。我很高兴这个比例已经逆转了。现在更多的人在谈论如何推动创新。

展望美国联邦政府之外，全球有许多司法区域。不幸的是，支持限制AI发展的监管论点仍在不断涌现。但我通过访问华盛顿和其他国家首都了解到，与监管机构交流确实能产生影响。如果你有机会与任何级别的监管机构交谈，我希望你能尽你所能帮助政府更好地理解AI。
